{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de locuteur : Chirac / Mitterrand üá´üá∑\n",
    "<center><img src=\"src/miterrand_chirac.jpg\" height=\"250\"></center>\n",
    "\n",
    "### Contenus:\n",
    "* Analyse exploratoire des donn√©es.\n",
    "* Traitement des donn√©es brutes:\n",
    "    * Segmentation en mots (*Tokenization*).\n",
    "    * Elimination des *stop-words*.\n",
    "    * Stemming/lemmatisation (racinisation).\n",
    "* Bag of Words.\n",
    "* TF et IDF.\n",
    "* Word2Vec.\n",
    "* Classifieurs:\n",
    "    * NB.\n",
    "    * Regression Logistique.\n",
    "    * SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import codecs\n",
    "import re\n",
    "import os.path\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = 'ressources/AFDpresidentutf8/corpus.tache1.learn.utf8'\n",
    "path_test = 'ressources/AFDpresidentutf8/corpus.tache1.test.utf8'\n",
    "path_test_lables = 'ressources/AFDpresidentutf8/ftlearn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse exploratoire des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous importons les donn√©es avec la fonction utilis√©e dans les notebooks du cours, qui utilise des expressions r√©guli√®res pour extraire l'√©tiquette et le contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_discours(fname):\n",
    "    alltxts = []\n",
    "    alllabs = []\n",
    "    s = codecs.open(fname, 'r','utf-8')\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
    "        if lab.count('M') > 0:\n",
    "            alllabs.append(-1)\n",
    "        else: \n",
    "            alllabs.append(1)\n",
    "        alltxts.append(txt)\n",
    "    return alltxts, alllabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, label = load_discours(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57413 57413\n",
      " Et ce sentiment n'est pas √©galement partag√©, monsieur le maire, mais enfin il existe de tous c√¥t√©s.\n",
      "\n",
      "-1\n",
      " Je compte sur vous.\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Chirac ----> 1\n",
    "# Mitterrand -> -1\n",
    "print(len(text),len(label))\n",
    "print(text[13])\n",
    "print(label[13])\n",
    "print(text[-1])\n",
    "print(label[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous r√©organisons l'ensemble de donn√©es dans un cadre de donn√©es pandas √† des fins de visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quand je dis chers amis, il ne s'agit pas l√† ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'abord merci de cet exceptionnel accueil que...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C'est toujours tr√®s √©mouvant de venir en Afri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aucun citoyen fran√ßais ne peut √™tre indiff√©re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le Congo, que nagu√®re le &lt;nom&gt; qualifia de \"r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   Quand je dis chers amis, il ne s'agit pas l√† ...      1\n",
       "1   D'abord merci de cet exceptionnel accueil que...      1\n",
       "2   C'est toujours tr√®s √©mouvant de venir en Afri...      1\n",
       "3   Aucun citoyen fran√ßais ne peut √™tre indiff√©re...      1\n",
       "4   Le Congo, que nagu√®re le <nom> qualifia de \"r...      1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'text':text, 'label':label})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57408</th>\n",
       "      <td>Je suis heureux de le mener avec vous.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57409</th>\n",
       "      <td>Vous le savez, comme vous, j'ai la passion de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57410</th>\n",
       "      <td>Je crois en son avenir.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57411</th>\n",
       "      <td>Je crois en la politique, c'est-√†-dire en not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57412</th>\n",
       "      <td>Je compte sur vous.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "57408           Je suis heureux de le mener avec vous.\\n      1\n",
       "57409   Vous le savez, comme vous, j'ai la passion de...      1\n",
       "57410                          Je crois en son avenir.\\n      1\n",
       "57411   Je crois en la politique, c'est-√†-dire en not...      1\n",
       "57412                              Je compte sur vous.\\n      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous souhaitons compter le nombre de discours prononc√©s par chaque pr√©sident, afin de v√©rifier si nous avons affaire √† un ensemble de donn√©es √©quilibr√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86093/3846337403.py:1: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.countplot(x='label', data=df, palette=[\"#4C0099\", \"#FFB3B3\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'Mitterand'), Text(1, 0, 'Chirac')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x='label', data=df, palette=[\"#4C0099\", \"#FFB3B3\"])\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(['Mitterand', 'Chirac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7523 phrases de Mitterand\n",
      "49890 phrases de Chirac\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(df[df[\"label\"]==-1])} phrases de Mitterand')\n",
    "print(f'{len(df[df[\"label\"]==1])} phrases de Chirac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"#4C0099\", \"#FFB3B3\"]\n",
    "\n",
    "fig, axs=plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "chrt_count = df[df['label'] == -1]['text'].str.len()\n",
    "axs[0].hist(chrt_count, color = colors[0], bins = 20, range = [0,1000])\n",
    "axs[0].set_title('Phrases de Mitterand')\n",
    "\n",
    "chrt_count = df[df['label'] == 1]['text'].str.len()\n",
    "axs[1].hist(chrt_count, color = colors[1], bins = 20, range = [0,1000])\n",
    "axs[1].set_title('Phrases de Chirac')\n",
    "\n",
    "fig.suptitle('Characters in phrases', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs=plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "mots_count = df[df['label'] == -1]['text'].str.split().map(lambda x: len(x))\n",
    "axs[0].hist(mots_count, color = colors[0], bins = 20, range = [0,150])\n",
    "axs[0].set_title('Phrases de Mitterand')\n",
    "\n",
    "mots_count = df[df['label'] == 1]['text'].str.split().map(lambda x: len(x))\n",
    "axs[1].hist(mots_count, color = colors[1], bins = 20, range = [0,150])\n",
    "axs[1].set_title('Phrases de Chirac')\n",
    "\n",
    "fig.suptitle('Mots in phrases', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour conclure cette premi√®re √©tape, nous nous int√©ressons aux statistiques descriptives de l'ensemble des donn√©es et de chaque interlocuteur √† l'√©chelle des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------ \n",
      "Pour toutes les phrases \n",
      "------------------------ \n",
      "count    57413.000000\n",
      "mean        21.535610\n",
      "std         14.336359\n",
      "min          1.000000\n",
      "25%         11.000000\n",
      "50%         18.000000\n",
      "75%         28.000000\n",
      "max        386.000000\n",
      "Name: text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('\\n------------------------',\n",
    "      '\\nPour toutes les phrases',\n",
    "      '\\n------------------------' ,\n",
    "      f\"\\n{df['text'].str.split().map(lambda x: len(x)).describe()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------ \n",
      "       Mitterand \n",
      "------------------------ \n",
      "count    7523.000000\n",
      "mean       26.840755\n",
      "std        19.784431\n",
      "min         1.000000\n",
      "25%        13.000000\n",
      "50%        22.000000\n",
      "75%        35.000000\n",
      "max       297.000000\n",
      "Name: text, dtype: float64\n",
      "\n",
      "------------------------ \n",
      "        Chirac \n",
      "------------------------ \n",
      "count    49890.000000\n",
      "mean        20.735638\n",
      "std         13.138622\n",
      "min          1.000000\n",
      "25%         11.000000\n",
      "50%         18.000000\n",
      "75%         27.000000\n",
      "max        386.000000\n",
      "Name: text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('\\n------------------------',\n",
    "      '\\n       Mitterand',\n",
    "      '\\n------------------------' ,\n",
    "      f\"\\n{df[df['label'] == -1]['text'].str.split().map(lambda x: len(x)).describe()}\")\n",
    "\n",
    "print('\\n------------------------',\n",
    "      '\\n        Chirac',\n",
    "      '\\n------------------------' ,\n",
    "      f\"\\n{df[df['label'] == 1]['text'].str.split().map(lambda x: len(x)).describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des donn√©es brutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "import codecs\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de pouvoir explorer diff√©rentes options de pr√©traitement, nous cr√©ons une fonction unique qui effectue les op√©rations suivantes : \n",
    "* Supprimer la ponctuation et les majuscules.\n",
    "* Supprimer les chiffres.\n",
    "* Transformer les phrases en une liste de tokens.\n",
    "* Lemmatiser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : La biblioth√®que FrenchLefffLemmatizer est utilis√©e, car la biblioth√®que NLTK (Natural Lenguage Toolkit), classique pour les t√¢ches de traitement automatique des langues, ne dispose pas d'un lemmatiseur robuste en fran√ßais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'm√™me', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', '√†', 'm', 'n', 's', 't', 'y', '√©t√©', '√©t√©e', '√©t√©es', '√©t√©s', '√©tant', '√©tante', '√©tants', '√©tantes', 'suis', 'es', 'est', 'sommes', '√™tes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', '√©tais', '√©tait', '√©tions', '√©tiez', '√©taient', 'fus', 'fut', 'f√ªmes', 'f√ªtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'f√ªt', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'e√ªmes', 'e√ªtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'e√ªt', 'eussions', 'eussiez', 'eussent']\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import stem\n",
    "\n",
    "\n",
    "stop_words = list(stopwords.words('french'))\n",
    "print(stop_words)\n",
    "lemmatizer = FrenchLefffLemmatizer()\n",
    "stemmer = SnowballStemmer(language='french')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous d√©finissons ensuite une fonction de pr√©traitement √† l'√©chelle du corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreprocessingCorpus(corpus, stop_words, lemmatizer, ap = True, pon = True, chif = True, stopw = True, lem = True, stem = True):\n",
    "    preprocessed_tokens = []\n",
    "    for phrase in corpus :\n",
    "        if ap:\n",
    "            new = re.sub(r'\\b\\w\\'(?=\\w)\\b', '', phrase) # sans_appostrophe\n",
    "        if pon:\n",
    "            new = re.sub(r'[^\\w\\s]', '', new).lower() # sans_ponctuation\n",
    "        if chif:\n",
    "            new = ''.join([mot for mot in new if not mot.isdigit()]) # sans_chiffres\n",
    "\n",
    "        new = nltk.tokenize.word_tokenize(new, language='french') # tokenize\n",
    "\n",
    "        if stopw:\n",
    "            new = [mot for mot in new if mot not in stop_words] # sans_stopwords\n",
    "        if lem:\n",
    "            new = [lemmatizer.lemmatize(mot) for mot in new] # lemmatize\n",
    "        if stem:\n",
    "            new = [stemmer.stem(mot) for mot in new]\n",
    "        \n",
    "        preprocessed_tokens.append(new)\n",
    "\n",
    "    corpus = list()\n",
    "    for phrase in preprocessed_tokens:\n",
    "        corpus.append(' '.join(phrase))\n",
    "        \n",
    "    return corpus, preprocessed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_corpus, tokenized = PreprocessingCorpus(text, stop_words, lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "with open('results/preprocessed.txt', 'w') as fp:\n",
    "    for i in preprocessed_corpus:\n",
    "        fp.write(\"%s\\n\" % i)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D'abord, on construit une classe pour calculer les valeaur d'accuracy, pr√©cision et rappel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "class tableResults(object):\n",
    "    def __init__(self) -> None:\n",
    "        self.__results = {'Model': list(),'Accuracy_tr' : list(), 'Balanced_accuracy_tr' : list(),\n",
    "                          'f1_tr' : list(), 'Accuracy_ts' : list(),'Balanced_accuracy_ts' : list(),\n",
    "                          'f1_ts' : list()}\n",
    "    \n",
    "    def evaluer(self,methodeName, ytr, yts, yhat_tr, yhat_ts) -> None:\n",
    "        acTr, bacTr, f1Tr, acTs, bacTs, f1Ts = (accuracy_score(ytr, yhat_tr),\\\n",
    "                                                            balanced_accuracy_score(ytr, yhat_tr),\\\n",
    "                                                            f1_score(ytr, yhat_tr),\\\n",
    "                                                            accuracy_score(yts, yhat_ts),\\\n",
    "                                                            balanced_accuracy_score(yts, yhat_ts),\\\n",
    "                                                            f1_score(yts, yhat_ts))\n",
    "        metrics = [acTr, bacTr, f1Tr, acTs, bacTs, f1Ts]\n",
    "        metrics_names = ['Accuracy_tr', 'Balanced_accuracy_tr', 'f1_tr',\n",
    "                         'Accuracy_ts', 'Balanced_accuracy_ts', 'f1_ts']\n",
    "        self.__results['Model'].append(methodeName)\n",
    "        for name, metric in zip(metrics_names, metrics):\n",
    "            self.__results[name].append(metric)   \n",
    "\n",
    "        print (f'-----------------------------IN TRAIN DATA-------------------------\\n\\\n",
    "               accuracy = {acTr}\\n\\\n",
    "               balanced_accuracy = {bacTr}\\n\\\n",
    "               f1 = {f1Tr}')\n",
    "        print (f'-----------------------------IN TEST DATA--------------------------\\n\\\n",
    "               accuracy = {acTs}\\n\\\n",
    "               balanced_accuracy = {bacTs}\\n\\\n",
    "               f1 = {f1Ts}')\n",
    "    \n",
    "    def afficher(self):\n",
    "        return pd.DataFrame(self.__results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats = tableResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence pour faire des experiences afin de tester des approches na√Øves sur la regression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57413, 28524)\n",
      "(57413,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer = 'word', ngram_range=(1, 1))\n",
    "X = vectorizer.fit_transform(text)\n",
    "y = np.array(label).squeeze()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.9357037995471398\n",
      "               balanced_accuracy = 0.9463292372009435\n",
      "               f1 = 0.9617796710448469\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8589758476544357\n",
      "               balanced_accuracy = 0.7745071434219812\n",
      "               f1 = 0.9164804181136746\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive1-LogisticRegression</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>0.96178</td>\n",
       "      <td>0.858976</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.91648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy_tr  Balanced_accuracy_tr    f1_tr  \\\n",
       "0  naive1-LogisticRegression     0.935704              0.946329  0.96178   \n",
       "\n",
       "   Accuracy_ts  Balanced_accuracy_ts    f1_ts  \n",
       "0     0.858976              0.774507  0.91648  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight = 'balanced', max_iter = 1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "yhat_train = logreg.predict(X_train)\n",
    "yhat_test = logreg.predict(X_test)\n",
    "resultats.evaluer('naive1-LogisticRegression', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57413, 28400)\n",
      "(57413,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words, analyzer = 'word', ngram_range=(1, 1))\n",
    "X = vectorizer.fit_transform(text)\n",
    "y = np.array(label).squeeze()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.9311751971932618\n",
      "               balanced_accuracy = 0.9408412414646966\n",
      "               f1 = 0.9590210080298674\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8472480260102183\n",
      "               balanced_accuracy = 0.7576149462699903\n",
      "               f1 = 0.909235174388519\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive1-LogisticRegression</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>0.961780</td>\n",
       "      <td>0.858976</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.916480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive2-LogisticRegression</td>\n",
       "      <td>0.931175</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy_tr  Balanced_accuracy_tr     f1_tr  \\\n",
       "0  naive1-LogisticRegression     0.935704              0.946329  0.961780   \n",
       "1  naive2-LogisticRegression     0.931175              0.940841  0.959021   \n",
       "\n",
       "   Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0     0.858976              0.774507  0.916480  \n",
       "1     0.847248              0.757615  0.909235  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight = 'balanced', max_iter = 1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "yhat_train = logreg.predict(X_train)\n",
    "yhat_test = logreg.predict(X_test)\n",
    "resultats.evaluer('naive2-LogisticRegression', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention certains mots de la liste des stopwords nous font perdre des informations !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57413, 25099)\n",
      "(57413,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_df = 0.0005, analyzer = 'word', ngram_range=(1, 1))\n",
    "X = vectorizer.fit_transform(text)\n",
    "y = np.array(label).squeeze()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.9112941352111275\n",
      "               balanced_accuracy = 0.8633983559149864\n",
      "               f1 = 0.9478412266455983\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8237923827217836\n",
      "               balanced_accuracy = 0.6513703663393935\n",
      "               f1 = 0.8972961997901933\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive1-LogisticRegression</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>0.961780</td>\n",
       "      <td>0.858976</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.916480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive2-LogisticRegression</td>\n",
       "      <td>0.931175</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive3-LogisticRegression</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>0.823792</td>\n",
       "      <td>0.651370</td>\n",
       "      <td>0.897296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy_tr  Balanced_accuracy_tr     f1_tr  \\\n",
       "0  naive1-LogisticRegression     0.935704              0.946329  0.961780   \n",
       "1  naive2-LogisticRegression     0.931175              0.940841  0.959021   \n",
       "2  naive3-LogisticRegression     0.911294              0.863398  0.947841   \n",
       "\n",
       "   Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0     0.858976              0.774507  0.916480  \n",
       "1     0.847248              0.757615  0.909235  \n",
       "2     0.823792              0.651370  0.897296  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight = 'balanced', max_iter = 1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "yhat_train = logreg.predict(X_train)\n",
    "yhat_test = logreg.predict(X_test)\n",
    "resultats.evaluer('naive3-LogisticRegression', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Ä partir de l√† et sur la base de multiples exp√©riences renfor√ßant la d√©couverte concernant les stop_words, il a √©t√© constat√© que pour cet ensemble de donn√©es et pour la liste de stop_words propos√©e dans nltk, les performances de tous les mod√®les de classification propos√©s diminuent. Apr√®s avoir explor√© le vocabulaire extrait √† l'aide de la fonction `get_feature_names_out()`. Nous concluons que cela est d√ª au fait que la liste contient des mots qui peuvent aider √† caract√©riser le ton d'un discours politique tels que : \"pour\" ou \"nous\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous commen√ßons maintenant √† √©valuer tous les mod√®les sur les donn√©es qui sont pass√©es par notre fonction de pr√©traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_corpus, tokenized = PreprocessingCorpus(text, stop_words, lemmatizer, stopw = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57413, 13643)\n",
      "(57413,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
    "X = vectorizer.fit_transform(preprocessed_corpus)\n",
    "y = np.array(label).squeeze()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.8928064893378785\n",
      "               balanced_accuracy = 0.8994643018815788\n",
      "               f1 = 0.9351575905355369\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8377844867626567\n",
      "               balanced_accuracy = 0.7782526686210816\n",
      "               f1 = 0.9021434575511348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive1-LogisticRegression</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>0.961780</td>\n",
       "      <td>0.858976</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.916480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive2-LogisticRegression</td>\n",
       "      <td>0.931175</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive3-LogisticRegression</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>0.823792</td>\n",
       "      <td>0.651370</td>\n",
       "      <td>0.897296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Accuracy_tr  Balanced_accuracy_tr  \\\n",
       "0       naive1-LogisticRegression     0.935704              0.946329   \n",
       "1       naive2-LogisticRegression     0.931175              0.940841   \n",
       "2       naive3-LogisticRegression     0.911294              0.863398   \n",
       "3  vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "4  vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "\n",
       "      f1_tr  Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0  0.961780     0.858976              0.774507  0.916480  \n",
       "1  0.959021     0.847248              0.757615  0.909235  \n",
       "2  0.947841     0.823792              0.651370  0.897296  \n",
       "3  0.935158     0.837784              0.778253  0.902143  \n",
       "4  0.935158     0.837784              0.778253  0.902143  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight = 'balanced', max_iter = 1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "yhat_train = logreg.predict(X_train)\n",
    "yhat_test = logreg.predict(X_test)\n",
    "resultats.evaluer('vectorizer1-LogisticRegression', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(class_weight = 'balanced')\n",
    "svc.fit(X_train, y_train)\n",
    "yhat_train = svc.predict(X_train)\n",
    "yhat_test = svc.predict(X_test)\n",
    "resultats.evaluer('vectorizer1-SVM', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight = 'balanced', max_depth=25, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "yhat_train = rf.predict(X_train)\n",
    "yhat_test = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats.evaluer('vectorizer1-RandomForest', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons maintenant d'autres options de pr√©traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57413, 40000)\n",
      "(57413,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(1, 2), max_features=40000)\n",
    "X = vectorizer2.fit_transform(preprocessed_corpus)\n",
    "y = np.array(label).squeeze()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(class_weight = 'balanced', max_iter = 1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "yhat_train = logreg.predict(X_train)\n",
    "yhat_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.9808902933638558\n",
      "               balanced_accuracy = 0.9862736816237594\n",
      "               f1 = 0.9888818113382363\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8857408267533674\n",
      "               balanced_accuracy = 0.7781784510940095\n",
      "               f1 = 0.933661430593946\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive1-LogisticRegression</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>0.961780</td>\n",
       "      <td>0.858976</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.916480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive2-LogisticRegression</td>\n",
       "      <td>0.931175</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive3-LogisticRegression</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>0.823792</td>\n",
       "      <td>0.651370</td>\n",
       "      <td>0.897296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.980890</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>0.988882</td>\n",
       "      <td>0.885741</td>\n",
       "      <td>0.778178</td>\n",
       "      <td>0.933661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.975690</td>\n",
       "      <td>0.982079</td>\n",
       "      <td>0.985819</td>\n",
       "      <td>0.879645</td>\n",
       "      <td>0.777171</td>\n",
       "      <td>0.929812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tf_idf1-LogisticRegression</td>\n",
       "      <td>0.859365</td>\n",
       "      <td>0.864765</td>\n",
       "      <td>0.913684</td>\n",
       "      <td>0.825128</td>\n",
       "      <td>0.784022</td>\n",
       "      <td>0.893184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tf_idf1-SVM</td>\n",
       "      <td>0.987409</td>\n",
       "      <td>0.992668</td>\n",
       "      <td>0.992695</td>\n",
       "      <td>0.899791</td>\n",
       "      <td>0.735254</td>\n",
       "      <td>0.943298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.909926</td>\n",
       "      <td>0.826934</td>\n",
       "      <td>0.947677</td>\n",
       "      <td>0.853751</td>\n",
       "      <td>0.704031</td>\n",
       "      <td>0.915177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.945607</td>\n",
       "      <td>0.866924</td>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.872503</td>\n",
       "      <td>0.674733</td>\n",
       "      <td>0.927853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.931449</td>\n",
       "      <td>0.846130</td>\n",
       "      <td>0.960576</td>\n",
       "      <td>0.863446</td>\n",
       "      <td>0.690045</td>\n",
       "      <td>0.921777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.936774</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.963657</td>\n",
       "      <td>0.867685</td>\n",
       "      <td>0.685768</td>\n",
       "      <td>0.924564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tf_idf2-LogisticRegression</td>\n",
       "      <td>0.917664</td>\n",
       "      <td>0.929220</td>\n",
       "      <td>0.950650</td>\n",
       "      <td>0.868149</td>\n",
       "      <td>0.799518</td>\n",
       "      <td>0.921784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tf_idf2-LogisticRegression</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>0.929125</td>\n",
       "      <td>0.950635</td>\n",
       "      <td>0.868207</td>\n",
       "      <td>0.799551</td>\n",
       "      <td>0.921821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vectorizer3-RandomForest</td>\n",
       "      <td>0.999801</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.881386</td>\n",
       "      <td>0.549864</td>\n",
       "      <td>0.936050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vectorizer2-RandomForest</td>\n",
       "      <td>0.999801</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.881386</td>\n",
       "      <td>0.549864</td>\n",
       "      <td>0.936050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.980890</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>0.988882</td>\n",
       "      <td>0.885741</td>\n",
       "      <td>0.778178</td>\n",
       "      <td>0.933661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy_tr  Balanced_accuracy_tr  \\\n",
       "0        naive1-LogisticRegression     0.935704              0.946329   \n",
       "1        naive2-LogisticRegression     0.931175              0.940841   \n",
       "2        naive3-LogisticRegression     0.911294              0.863398   \n",
       "3   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "4   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "5   vectorizer2-LogisticRegression     0.980890              0.986274   \n",
       "6   vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "7   vectorizer3-LogisticRegression     0.975690              0.982079   \n",
       "8   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "9   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "10  vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "11      tf_idf1-LogisticRegression     0.859365              0.864765   \n",
       "12                     tf_idf1-SVM     0.987409              0.992668   \n",
       "13            tf_idf1-RandomForest     0.909926              0.826934   \n",
       "14            tf_idf1-RandomForest     0.945607              0.866924   \n",
       "15            tf_idf1-RandomForest     0.931449              0.846130   \n",
       "16            tf_idf1-RandomForest     0.936774              0.856317   \n",
       "17      tf_idf2-LogisticRegression     0.917664              0.929220   \n",
       "18      tf_idf2-LogisticRegression     0.917639              0.929125   \n",
       "19        vectorizer3-RandomForest     0.999801              0.999405   \n",
       "20        vectorizer2-RandomForest     0.999801              0.999405   \n",
       "21  vectorizer2-LogisticRegression     0.980890              0.986274   \n",
       "\n",
       "       f1_tr  Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0   0.961780     0.858976              0.774507  0.916480  \n",
       "1   0.959021     0.847248              0.757615  0.909235  \n",
       "2   0.947841     0.823792              0.651370  0.897296  \n",
       "3   0.935158     0.837784              0.778253  0.902143  \n",
       "4   0.935158     0.837784              0.778253  0.902143  \n",
       "5   0.988882     0.885741              0.778178  0.933661  \n",
       "6   0.991655     0.888121              0.777245  0.935185  \n",
       "7   0.985819     0.879645              0.777171  0.929812  \n",
       "8   0.989161     0.884464              0.778020  0.932856  \n",
       "9   0.989161     0.884464              0.778020  0.932856  \n",
       "10  0.991655     0.888121              0.777245  0.935185  \n",
       "11  0.913684     0.825128              0.784022  0.893184  \n",
       "12  0.992695     0.899791              0.735254  0.943298  \n",
       "13  0.947677     0.853751              0.704031  0.915177  \n",
       "14  0.968831     0.872503              0.674733  0.927853  \n",
       "15  0.960576     0.863446              0.690045  0.921777  \n",
       "16  0.963657     0.867685              0.685768  0.924564  \n",
       "17  0.950650     0.868149              0.799518  0.921784  \n",
       "18  0.950635     0.868207              0.799551  0.921821  \n",
       "19  0.999885     0.881386              0.549864  0.936050  \n",
       "20  0.999885     0.881386              0.549864  0.936050  \n",
       "21  0.988882     0.885741              0.778178  0.933661  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultats.evaluer('vectorizer2-LogisticRegression', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(class_weight = 'balanced')\n",
    "svc.fit(X_train, y_train)\n",
    "yhat_train = svc.predict(X_train)\n",
    "yhat_test = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.9712856751847521\n",
      "               balanced_accuracy = 0.9713028439598625\n",
      "               f1 = 0.983257406493921\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8756386437529029\n",
      "               balanced_accuracy = 0.6772991923909095\n",
      "               f1 = 0.9297336307571183\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.929533</td>\n",
       "      <td>0.895021</td>\n",
       "      <td>0.958690</td>\n",
       "      <td>0.835752</td>\n",
       "      <td>0.691591</td>\n",
       "      <td>0.903805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vectorizer1-SVM</td>\n",
       "      <td>0.956804</td>\n",
       "      <td>0.914648</td>\n",
       "      <td>0.975040</td>\n",
       "      <td>0.859150</td>\n",
       "      <td>0.599974</td>\n",
       "      <td>0.921509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vectorizer1-RandomForest</td>\n",
       "      <td>0.903456</td>\n",
       "      <td>0.941034</td>\n",
       "      <td>0.941194</td>\n",
       "      <td>0.696993</td>\n",
       "      <td>0.657366</td>\n",
       "      <td>0.803390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.962378</td>\n",
       "      <td>0.966572</td>\n",
       "      <td>0.977946</td>\n",
       "      <td>0.868439</td>\n",
       "      <td>0.768055</td>\n",
       "      <td>0.922846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vectorizer2-SVM</td>\n",
       "      <td>0.971286</td>\n",
       "      <td>0.971303</td>\n",
       "      <td>0.983257</td>\n",
       "      <td>0.875639</td>\n",
       "      <td>0.677299</td>\n",
       "      <td>0.929734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Accuracy_tr  Balanced_accuracy_tr  \\\n",
       "0  vectorizer1-LogisticRegression     0.929533              0.895021   \n",
       "1                 vectorizer1-SVM     0.956804              0.914648   \n",
       "2        vectorizer1-RandomForest     0.903456              0.941034   \n",
       "3  vectorizer2-LogisticRegression     0.962378              0.966572   \n",
       "4                 vectorizer2-SVM     0.971286              0.971303   \n",
       "\n",
       "      f1_tr  Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0  0.958690     0.835752              0.691591  0.903805  \n",
       "1  0.975040     0.859150              0.599974  0.921509  \n",
       "2  0.941194     0.696993              0.657366  0.803390  \n",
       "3  0.977946     0.868439              0.768055  0.922846  \n",
       "4  0.983257     0.875639              0.677299  0.929734  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultats.evaluer('vectorizer2-SVM', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight = 'balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "yhat_train = rf.predict(X_train)\n",
    "yhat_test = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.9076613003558187\n",
      "               balanced_accuracy = 0.8000334138475341\n",
      "               f1 = 0.9467842546784254\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8576405016256387\n",
      "               balanced_accuracy = 0.7150823334566492\n",
      "               f1 = 0.9173631706659477\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive1-LogisticRegression</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>0.961780</td>\n",
       "      <td>0.858976</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.916480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive2-LogisticRegression</td>\n",
       "      <td>0.931175</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive3-LogisticRegression</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>0.823792</td>\n",
       "      <td>0.651370</td>\n",
       "      <td>0.897296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.980890</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>0.988882</td>\n",
       "      <td>0.885741</td>\n",
       "      <td>0.778178</td>\n",
       "      <td>0.933661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.975690</td>\n",
       "      <td>0.982079</td>\n",
       "      <td>0.985819</td>\n",
       "      <td>0.879645</td>\n",
       "      <td>0.777171</td>\n",
       "      <td>0.929812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tf_idf1-LogisticRegression</td>\n",
       "      <td>0.859365</td>\n",
       "      <td>0.864765</td>\n",
       "      <td>0.913684</td>\n",
       "      <td>0.825128</td>\n",
       "      <td>0.784022</td>\n",
       "      <td>0.893184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tf_idf1-SVM</td>\n",
       "      <td>0.987409</td>\n",
       "      <td>0.992668</td>\n",
       "      <td>0.992695</td>\n",
       "      <td>0.899791</td>\n",
       "      <td>0.735254</td>\n",
       "      <td>0.943298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.909926</td>\n",
       "      <td>0.826934</td>\n",
       "      <td>0.947677</td>\n",
       "      <td>0.853751</td>\n",
       "      <td>0.704031</td>\n",
       "      <td>0.915177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.945607</td>\n",
       "      <td>0.866924</td>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.872503</td>\n",
       "      <td>0.674733</td>\n",
       "      <td>0.927853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.931449</td>\n",
       "      <td>0.846130</td>\n",
       "      <td>0.960576</td>\n",
       "      <td>0.863446</td>\n",
       "      <td>0.690045</td>\n",
       "      <td>0.921777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.936774</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.963657</td>\n",
       "      <td>0.867685</td>\n",
       "      <td>0.685768</td>\n",
       "      <td>0.924564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tf_idf2-LogisticRegression</td>\n",
       "      <td>0.917664</td>\n",
       "      <td>0.929220</td>\n",
       "      <td>0.950650</td>\n",
       "      <td>0.868149</td>\n",
       "      <td>0.799518</td>\n",
       "      <td>0.921784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tf_idf2-LogisticRegression</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>0.929125</td>\n",
       "      <td>0.950635</td>\n",
       "      <td>0.868207</td>\n",
       "      <td>0.799551</td>\n",
       "      <td>0.921821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vectorizer3-RandomForest</td>\n",
       "      <td>0.999801</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.881386</td>\n",
       "      <td>0.549864</td>\n",
       "      <td>0.936050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vectorizer2-RandomForest</td>\n",
       "      <td>0.999801</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.881386</td>\n",
       "      <td>0.549864</td>\n",
       "      <td>0.936050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.980890</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>0.988882</td>\n",
       "      <td>0.885741</td>\n",
       "      <td>0.778178</td>\n",
       "      <td>0.933661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vectorizer2-RandomForest</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.879529</td>\n",
       "      <td>0.537679</td>\n",
       "      <td>0.935219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vectorizer2-RandomForest</td>\n",
       "      <td>0.907661</td>\n",
       "      <td>0.800033</td>\n",
       "      <td>0.946784</td>\n",
       "      <td>0.857641</td>\n",
       "      <td>0.715082</td>\n",
       "      <td>0.917363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy_tr  Balanced_accuracy_tr  \\\n",
       "0        naive1-LogisticRegression     0.935704              0.946329   \n",
       "1        naive2-LogisticRegression     0.931175              0.940841   \n",
       "2        naive3-LogisticRegression     0.911294              0.863398   \n",
       "3   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "4   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "5   vectorizer2-LogisticRegression     0.980890              0.986274   \n",
       "6   vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "7   vectorizer3-LogisticRegression     0.975690              0.982079   \n",
       "8   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "9   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "10  vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "11      tf_idf1-LogisticRegression     0.859365              0.864765   \n",
       "12                     tf_idf1-SVM     0.987409              0.992668   \n",
       "13            tf_idf1-RandomForest     0.909926              0.826934   \n",
       "14            tf_idf1-RandomForest     0.945607              0.866924   \n",
       "15            tf_idf1-RandomForest     0.931449              0.846130   \n",
       "16            tf_idf1-RandomForest     0.936774              0.856317   \n",
       "17      tf_idf2-LogisticRegression     0.917664              0.929220   \n",
       "18      tf_idf2-LogisticRegression     0.917639              0.929125   \n",
       "19        vectorizer3-RandomForest     0.999801              0.999405   \n",
       "20        vectorizer2-RandomForest     0.999801              0.999405   \n",
       "21  vectorizer2-LogisticRegression     0.980890              0.986274   \n",
       "22        vectorizer2-RandomForest     0.999826              0.999580   \n",
       "23        vectorizer2-RandomForest     0.907661              0.800033   \n",
       "\n",
       "       f1_tr  Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0   0.961780     0.858976              0.774507  0.916480  \n",
       "1   0.959021     0.847248              0.757615  0.909235  \n",
       "2   0.947841     0.823792              0.651370  0.897296  \n",
       "3   0.935158     0.837784              0.778253  0.902143  \n",
       "4   0.935158     0.837784              0.778253  0.902143  \n",
       "5   0.988882     0.885741              0.778178  0.933661  \n",
       "6   0.991655     0.888121              0.777245  0.935185  \n",
       "7   0.985819     0.879645              0.777171  0.929812  \n",
       "8   0.989161     0.884464              0.778020  0.932856  \n",
       "9   0.989161     0.884464              0.778020  0.932856  \n",
       "10  0.991655     0.888121              0.777245  0.935185  \n",
       "11  0.913684     0.825128              0.784022  0.893184  \n",
       "12  0.992695     0.899791              0.735254  0.943298  \n",
       "13  0.947677     0.853751              0.704031  0.915177  \n",
       "14  0.968831     0.872503              0.674733  0.927853  \n",
       "15  0.960576     0.863446              0.690045  0.921777  \n",
       "16  0.963657     0.867685              0.685768  0.924564  \n",
       "17  0.950650     0.868149              0.799518  0.921784  \n",
       "18  0.950635     0.868207              0.799551  0.921821  \n",
       "19  0.999885     0.881386              0.549864  0.936050  \n",
       "20  0.999885     0.881386              0.549864  0.936050  \n",
       "21  0.988882     0.885741              0.778178  0.933661  \n",
       "22  0.999900     0.879529              0.537679  0.935219  \n",
       "23  0.946784     0.857641              0.715082  0.917363  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultats.evaluer('vectorizer2-RandomForest', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons les trois mod√®les avec une troisi√®me approximation du sac de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57413, 50000)\n",
      "(57413,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(1, 3), max_features=50000)\n",
    "X = vectorizer2.fit_transform(preprocessed_corpus)\n",
    "y = np.array(label).squeeze()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.9856179551618602\n",
      "               balanced_accuracy = 0.9890766711865877\n",
      "               f1 = 0.9916551166551166\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8881212261960055\n",
      "               balanced_accuracy = 0.7772446122095211\n",
      "               f1 = 0.9351854966196899\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive1-LogisticRegression</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>0.961780</td>\n",
       "      <td>0.858976</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.916480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive2-LogisticRegression</td>\n",
       "      <td>0.931175</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive3-LogisticRegression</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>0.823792</td>\n",
       "      <td>0.651370</td>\n",
       "      <td>0.897296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.980890</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>0.988882</td>\n",
       "      <td>0.885741</td>\n",
       "      <td>0.778178</td>\n",
       "      <td>0.933661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.975690</td>\n",
       "      <td>0.982079</td>\n",
       "      <td>0.985819</td>\n",
       "      <td>0.879645</td>\n",
       "      <td>0.777171</td>\n",
       "      <td>0.929812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy_tr  Balanced_accuracy_tr  \\\n",
       "0        naive1-LogisticRegression     0.935704              0.946329   \n",
       "1        naive2-LogisticRegression     0.931175              0.940841   \n",
       "2        naive3-LogisticRegression     0.911294              0.863398   \n",
       "3   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "4   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "5   vectorizer2-LogisticRegression     0.980890              0.986274   \n",
       "6   vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "7   vectorizer3-LogisticRegression     0.975690              0.982079   \n",
       "8   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "9   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "10  vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "\n",
       "       f1_tr  Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0   0.961780     0.858976              0.774507  0.916480  \n",
       "1   0.959021     0.847248              0.757615  0.909235  \n",
       "2   0.947841     0.823792              0.651370  0.897296  \n",
       "3   0.935158     0.837784              0.778253  0.902143  \n",
       "4   0.935158     0.837784              0.778253  0.902143  \n",
       "5   0.988882     0.885741              0.778178  0.933661  \n",
       "6   0.991655     0.888121              0.777245  0.935185  \n",
       "7   0.985819     0.879645              0.777171  0.929812  \n",
       "8   0.989161     0.884464              0.778020  0.932856  \n",
       "9   0.989161     0.884464              0.778020  0.932856  \n",
       "10  0.991655     0.888121              0.777245  0.935185  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight = 'balanced', max_iter = 1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "yhat_train = logreg.predict(X_train)\n",
    "yhat_test = logreg.predict(X_test)\n",
    "resultats.evaluer('vectorizer3-LogisticRegression', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.9998009405558735\n",
      "               balanced_accuracy = 0.9994054058929231\n",
      "               f1 = 0.9998853539696188\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8813864375290292\n",
      "               balanced_accuracy = 0.5498637085412315\n",
      "               f1 = 0.9360503333646352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive1-LogisticRegression</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>0.961780</td>\n",
       "      <td>0.858976</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.916480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive2-LogisticRegression</td>\n",
       "      <td>0.931175</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive3-LogisticRegression</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>0.823792</td>\n",
       "      <td>0.651370</td>\n",
       "      <td>0.897296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.980890</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>0.988882</td>\n",
       "      <td>0.885741</td>\n",
       "      <td>0.778178</td>\n",
       "      <td>0.933661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.975690</td>\n",
       "      <td>0.982079</td>\n",
       "      <td>0.985819</td>\n",
       "      <td>0.879645</td>\n",
       "      <td>0.777171</td>\n",
       "      <td>0.929812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tf_idf1-LogisticRegression</td>\n",
       "      <td>0.859365</td>\n",
       "      <td>0.864765</td>\n",
       "      <td>0.913684</td>\n",
       "      <td>0.825128</td>\n",
       "      <td>0.784022</td>\n",
       "      <td>0.893184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tf_idf1-SVM</td>\n",
       "      <td>0.987409</td>\n",
       "      <td>0.992668</td>\n",
       "      <td>0.992695</td>\n",
       "      <td>0.899791</td>\n",
       "      <td>0.735254</td>\n",
       "      <td>0.943298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.909926</td>\n",
       "      <td>0.826934</td>\n",
       "      <td>0.947677</td>\n",
       "      <td>0.853751</td>\n",
       "      <td>0.704031</td>\n",
       "      <td>0.915177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.945607</td>\n",
       "      <td>0.866924</td>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.872503</td>\n",
       "      <td>0.674733</td>\n",
       "      <td>0.927853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.931449</td>\n",
       "      <td>0.846130</td>\n",
       "      <td>0.960576</td>\n",
       "      <td>0.863446</td>\n",
       "      <td>0.690045</td>\n",
       "      <td>0.921777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.936774</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.963657</td>\n",
       "      <td>0.867685</td>\n",
       "      <td>0.685768</td>\n",
       "      <td>0.924564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tf_idf2-LogisticRegression</td>\n",
       "      <td>0.917664</td>\n",
       "      <td>0.929220</td>\n",
       "      <td>0.950650</td>\n",
       "      <td>0.868149</td>\n",
       "      <td>0.799518</td>\n",
       "      <td>0.921784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tf_idf2-LogisticRegression</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>0.929125</td>\n",
       "      <td>0.950635</td>\n",
       "      <td>0.868207</td>\n",
       "      <td>0.799551</td>\n",
       "      <td>0.921821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vectorizer3-RandomForest</td>\n",
       "      <td>0.999801</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.881386</td>\n",
       "      <td>0.549864</td>\n",
       "      <td>0.936050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy_tr  Balanced_accuracy_tr  \\\n",
       "0        naive1-LogisticRegression     0.935704              0.946329   \n",
       "1        naive2-LogisticRegression     0.931175              0.940841   \n",
       "2        naive3-LogisticRegression     0.911294              0.863398   \n",
       "3   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "4   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "5   vectorizer2-LogisticRegression     0.980890              0.986274   \n",
       "6   vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "7   vectorizer3-LogisticRegression     0.975690              0.982079   \n",
       "8   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "9   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "10  vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "11      tf_idf1-LogisticRegression     0.859365              0.864765   \n",
       "12                     tf_idf1-SVM     0.987409              0.992668   \n",
       "13            tf_idf1-RandomForest     0.909926              0.826934   \n",
       "14            tf_idf1-RandomForest     0.945607              0.866924   \n",
       "15            tf_idf1-RandomForest     0.931449              0.846130   \n",
       "16            tf_idf1-RandomForest     0.936774              0.856317   \n",
       "17      tf_idf2-LogisticRegression     0.917664              0.929220   \n",
       "18      tf_idf2-LogisticRegression     0.917639              0.929125   \n",
       "19        vectorizer3-RandomForest     0.999801              0.999405   \n",
       "\n",
       "       f1_tr  Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0   0.961780     0.858976              0.774507  0.916480  \n",
       "1   0.959021     0.847248              0.757615  0.909235  \n",
       "2   0.947841     0.823792              0.651370  0.897296  \n",
       "3   0.935158     0.837784              0.778253  0.902143  \n",
       "4   0.935158     0.837784              0.778253  0.902143  \n",
       "5   0.988882     0.885741              0.778178  0.933661  \n",
       "6   0.991655     0.888121              0.777245  0.935185  \n",
       "7   0.985819     0.879645              0.777171  0.929812  \n",
       "8   0.989161     0.884464              0.778020  0.932856  \n",
       "9   0.989161     0.884464              0.778020  0.932856  \n",
       "10  0.991655     0.888121              0.777245  0.935185  \n",
       "11  0.913684     0.825128              0.784022  0.893184  \n",
       "12  0.992695     0.899791              0.735254  0.943298  \n",
       "13  0.947677     0.853751              0.704031  0.915177  \n",
       "14  0.968831     0.872503              0.674733  0.927853  \n",
       "15  0.960576     0.863446              0.690045  0.921777  \n",
       "16  0.963657     0.867685              0.685768  0.924564  \n",
       "17  0.950650     0.868149              0.799518  0.921784  \n",
       "18  0.950635     0.868207              0.799551  0.921821  \n",
       "19  0.999885     0.881386              0.549864  0.936050  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight = 'balanced', random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "yhat_train = rf.predict(X_train)\n",
    "yhat_test = rf.predict(X_test)\n",
    "resultats.evaluer('vectorizer3-RandomForest', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En examinant les r√©sultats historiques, il est √©vident que notre for√™t al√©atoire sur-apprendre sur l'ensemble d'apprentissage. Compte tenu du temps d'ex√©cution de chaque √©tape de ce projet, nous ne pouvons pas faire un selection exhaustive d'hyperparam√®tres, pour r√©soudre ce probl√®me. Au lieu de cela, sur la base de la connaissance du fonctionnement math√©matique de la m√©thode, nous diminuerons manuellement la profondeur de chaque arbre et analyserons les changements que cela apporte aux scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight = 'balanced', max_depth=25, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "yhat_train = rf.predict(X_train)\n",
    "yhat_test = rf.predict(X_test)\n",
    "resultats.evaluer('vectorizer3-RandomForest', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons r√©ussi √† combattre le sur-apprentissage, mais il semble que la r√©gression logistique et la SVM soient plus prometteuses, c'est pourquoi nous arr√™terons d'utiliser la m√©thode de la for√™t al√©atoire dans les prochaines it√©rations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57413, 13643)\n",
      "(57413,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "tf_idf = Pipeline([('count', CountVectorizer(analyzer='word', ngram_range=(1, 1))),\n",
    "                 ('tfid', TfidfTransformer())])\n",
    "\n",
    "X = tf_idf.fit_transform(preprocessed_corpus)\n",
    "y = np.array(label).squeeze()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(class_weight = 'balanced', random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "yhat_train = logreg.predict(X_train)\n",
    "yhat_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.8593645027246262\n",
      "               balanced_accuracy = 0.8647645462488615\n",
      "               f1 = 0.9136835675015272\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8251277287505806\n",
      "               balanced_accuracy = 0.7840221363824158\n",
      "               f1 = 0.8931839137527485\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive1-LogisticRegression</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>0.961780</td>\n",
       "      <td>0.858976</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.916480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive2-LogisticRegression</td>\n",
       "      <td>0.931175</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive3-LogisticRegression</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>0.823792</td>\n",
       "      <td>0.651370</td>\n",
       "      <td>0.897296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.980890</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>0.988882</td>\n",
       "      <td>0.885741</td>\n",
       "      <td>0.778178</td>\n",
       "      <td>0.933661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.975690</td>\n",
       "      <td>0.982079</td>\n",
       "      <td>0.985819</td>\n",
       "      <td>0.879645</td>\n",
       "      <td>0.777171</td>\n",
       "      <td>0.929812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tf_idf1-LogisticRegression</td>\n",
       "      <td>0.859365</td>\n",
       "      <td>0.864765</td>\n",
       "      <td>0.913684</td>\n",
       "      <td>0.825128</td>\n",
       "      <td>0.784022</td>\n",
       "      <td>0.893184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy_tr  Balanced_accuracy_tr  \\\n",
       "0        naive1-LogisticRegression     0.935704              0.946329   \n",
       "1        naive2-LogisticRegression     0.931175              0.940841   \n",
       "2        naive3-LogisticRegression     0.911294              0.863398   \n",
       "3   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "4   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "5   vectorizer2-LogisticRegression     0.980890              0.986274   \n",
       "6   vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "7   vectorizer3-LogisticRegression     0.975690              0.982079   \n",
       "8   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "9   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "10  vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "11      tf_idf1-LogisticRegression     0.859365              0.864765   \n",
       "\n",
       "       f1_tr  Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0   0.961780     0.858976              0.774507  0.916480  \n",
       "1   0.959021     0.847248              0.757615  0.909235  \n",
       "2   0.947841     0.823792              0.651370  0.897296  \n",
       "3   0.935158     0.837784              0.778253  0.902143  \n",
       "4   0.935158     0.837784              0.778253  0.902143  \n",
       "5   0.988882     0.885741              0.778178  0.933661  \n",
       "6   0.991655     0.888121              0.777245  0.935185  \n",
       "7   0.985819     0.879645              0.777171  0.929812  \n",
       "8   0.989161     0.884464              0.778020  0.932856  \n",
       "9   0.989161     0.884464              0.778020  0.932856  \n",
       "10  0.991655     0.888121              0.777245  0.935185  \n",
       "11  0.913684     0.825128              0.784022  0.893184  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultats.evaluer('tf_idf1-LogisticRegression', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(class_weight = 'balanced')\n",
    "svc.fit(X_train, y_train)\n",
    "yhat_train = svc.predict(X_train)\n",
    "yhat_test = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.9874094901589987\n",
      "               balanced_accuracy = 0.9926682326339157\n",
      "               f1 = 0.9926954613696731\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8997909893172318\n",
      "               balanced_accuracy = 0.7352535413520022\n",
      "               f1 = 0.9432982917214192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive1-LogisticRegression</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>0.961780</td>\n",
       "      <td>0.858976</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.916480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive2-LogisticRegression</td>\n",
       "      <td>0.931175</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive3-LogisticRegression</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>0.823792</td>\n",
       "      <td>0.651370</td>\n",
       "      <td>0.897296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.980890</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>0.988882</td>\n",
       "      <td>0.885741</td>\n",
       "      <td>0.778178</td>\n",
       "      <td>0.933661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.975690</td>\n",
       "      <td>0.982079</td>\n",
       "      <td>0.985819</td>\n",
       "      <td>0.879645</td>\n",
       "      <td>0.777171</td>\n",
       "      <td>0.929812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tf_idf1-LogisticRegression</td>\n",
       "      <td>0.859365</td>\n",
       "      <td>0.864765</td>\n",
       "      <td>0.913684</td>\n",
       "      <td>0.825128</td>\n",
       "      <td>0.784022</td>\n",
       "      <td>0.893184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tf_idf1-SVM</td>\n",
       "      <td>0.987409</td>\n",
       "      <td>0.992668</td>\n",
       "      <td>0.992695</td>\n",
       "      <td>0.899791</td>\n",
       "      <td>0.735254</td>\n",
       "      <td>0.943298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy_tr  Balanced_accuracy_tr  \\\n",
       "0        naive1-LogisticRegression     0.935704              0.946329   \n",
       "1        naive2-LogisticRegression     0.931175              0.940841   \n",
       "2        naive3-LogisticRegression     0.911294              0.863398   \n",
       "3   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "4   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "5   vectorizer2-LogisticRegression     0.980890              0.986274   \n",
       "6   vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "7   vectorizer3-LogisticRegression     0.975690              0.982079   \n",
       "8   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "9   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "10  vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "11      tf_idf1-LogisticRegression     0.859365              0.864765   \n",
       "12                     tf_idf1-SVM     0.987409              0.992668   \n",
       "\n",
       "       f1_tr  Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0   0.961780     0.858976              0.774507  0.916480  \n",
       "1   0.959021     0.847248              0.757615  0.909235  \n",
       "2   0.947841     0.823792              0.651370  0.897296  \n",
       "3   0.935158     0.837784              0.778253  0.902143  \n",
       "4   0.935158     0.837784              0.778253  0.902143  \n",
       "5   0.988882     0.885741              0.778178  0.933661  \n",
       "6   0.991655     0.888121              0.777245  0.935185  \n",
       "7   0.985819     0.879645              0.777171  0.929812  \n",
       "8   0.989161     0.884464              0.778020  0.932856  \n",
       "9   0.989161     0.884464              0.778020  0.932856  \n",
       "10  0.991655     0.888121              0.777245  0.935185  \n",
       "11  0.913684     0.825128              0.784022  0.893184  \n",
       "12  0.992695     0.899791              0.735254  0.943298  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultats.evaluer('tf_idf1-SVM', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ajoutons maintenant √† `vectorize2`, le transformateur TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57413, 50000)\n",
      "(57413,)\n"
     ]
    }
   ],
   "source": [
    "tf_idf = Pipeline([('count', CountVectorizer(analyzer='word', ngram_range=(1, 2), max_features=50000)),\n",
    "                 ('tfid', TfidfTransformer())])\n",
    "\n",
    "X = tf_idf.fit_transform(preprocessed_corpus)\n",
    "y = np.array(label).squeeze()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.9176391549926597\n",
      "               balanced_accuracy = 0.9291253422004935\n",
      "               f1 = 0.9506353278052855\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.8682071528100325\n",
      "               balanced_accuracy = 0.799550878964713\n",
      "               f1 = 0.92182118749139\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive1-LogisticRegression</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>0.961780</td>\n",
       "      <td>0.858976</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.916480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive2-LogisticRegression</td>\n",
       "      <td>0.931175</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive3-LogisticRegression</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>0.823792</td>\n",
       "      <td>0.651370</td>\n",
       "      <td>0.897296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>0.899464</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.778253</td>\n",
       "      <td>0.902143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.980890</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>0.988882</td>\n",
       "      <td>0.885741</td>\n",
       "      <td>0.778178</td>\n",
       "      <td>0.933661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.975690</td>\n",
       "      <td>0.982079</td>\n",
       "      <td>0.985819</td>\n",
       "      <td>0.879645</td>\n",
       "      <td>0.777171</td>\n",
       "      <td>0.929812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.932856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vectorizer3-LogisticRegression</td>\n",
       "      <td>0.985618</td>\n",
       "      <td>0.989077</td>\n",
       "      <td>0.991655</td>\n",
       "      <td>0.888121</td>\n",
       "      <td>0.777245</td>\n",
       "      <td>0.935185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tf_idf1-LogisticRegression</td>\n",
       "      <td>0.859365</td>\n",
       "      <td>0.864765</td>\n",
       "      <td>0.913684</td>\n",
       "      <td>0.825128</td>\n",
       "      <td>0.784022</td>\n",
       "      <td>0.893184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tf_idf1-SVM</td>\n",
       "      <td>0.987409</td>\n",
       "      <td>0.992668</td>\n",
       "      <td>0.992695</td>\n",
       "      <td>0.899791</td>\n",
       "      <td>0.735254</td>\n",
       "      <td>0.943298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.909926</td>\n",
       "      <td>0.826934</td>\n",
       "      <td>0.947677</td>\n",
       "      <td>0.853751</td>\n",
       "      <td>0.704031</td>\n",
       "      <td>0.915177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.945607</td>\n",
       "      <td>0.866924</td>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.872503</td>\n",
       "      <td>0.674733</td>\n",
       "      <td>0.927853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.931449</td>\n",
       "      <td>0.846130</td>\n",
       "      <td>0.960576</td>\n",
       "      <td>0.863446</td>\n",
       "      <td>0.690045</td>\n",
       "      <td>0.921777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.936774</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.963657</td>\n",
       "      <td>0.867685</td>\n",
       "      <td>0.685768</td>\n",
       "      <td>0.924564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tf_idf2-LogisticRegression</td>\n",
       "      <td>0.917664</td>\n",
       "      <td>0.929220</td>\n",
       "      <td>0.950650</td>\n",
       "      <td>0.868149</td>\n",
       "      <td>0.799518</td>\n",
       "      <td>0.921784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tf_idf2-LogisticRegression</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>0.929125</td>\n",
       "      <td>0.950635</td>\n",
       "      <td>0.868207</td>\n",
       "      <td>0.799551</td>\n",
       "      <td>0.921821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vectorizer3-RandomForest</td>\n",
       "      <td>0.999801</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.881386</td>\n",
       "      <td>0.549864</td>\n",
       "      <td>0.936050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vectorizer2-RandomForest</td>\n",
       "      <td>0.999801</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.881386</td>\n",
       "      <td>0.549864</td>\n",
       "      <td>0.936050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.980890</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>0.988882</td>\n",
       "      <td>0.885741</td>\n",
       "      <td>0.778178</td>\n",
       "      <td>0.933661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vectorizer2-RandomForest</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.879529</td>\n",
       "      <td>0.537679</td>\n",
       "      <td>0.935219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vectorizer2-RandomForest</td>\n",
       "      <td>0.907661</td>\n",
       "      <td>0.800033</td>\n",
       "      <td>0.946784</td>\n",
       "      <td>0.857641</td>\n",
       "      <td>0.715082</td>\n",
       "      <td>0.917363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tf_idf2-LogisticRegression</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>0.929125</td>\n",
       "      <td>0.950635</td>\n",
       "      <td>0.868207</td>\n",
       "      <td>0.799551</td>\n",
       "      <td>0.921821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy_tr  Balanced_accuracy_tr  \\\n",
       "0        naive1-LogisticRegression     0.935704              0.946329   \n",
       "1        naive2-LogisticRegression     0.931175              0.940841   \n",
       "2        naive3-LogisticRegression     0.911294              0.863398   \n",
       "3   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "4   vectorizer1-LogisticRegression     0.892806              0.899464   \n",
       "5   vectorizer2-LogisticRegression     0.980890              0.986274   \n",
       "6   vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "7   vectorizer3-LogisticRegression     0.975690              0.982079   \n",
       "8   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "9   vectorizer3-LogisticRegression     0.981363              0.986226   \n",
       "10  vectorizer3-LogisticRegression     0.985618              0.989077   \n",
       "11      tf_idf1-LogisticRegression     0.859365              0.864765   \n",
       "12                     tf_idf1-SVM     0.987409              0.992668   \n",
       "13            tf_idf1-RandomForest     0.909926              0.826934   \n",
       "14            tf_idf1-RandomForest     0.945607              0.866924   \n",
       "15            tf_idf1-RandomForest     0.931449              0.846130   \n",
       "16            tf_idf1-RandomForest     0.936774              0.856317   \n",
       "17      tf_idf2-LogisticRegression     0.917664              0.929220   \n",
       "18      tf_idf2-LogisticRegression     0.917639              0.929125   \n",
       "19        vectorizer3-RandomForest     0.999801              0.999405   \n",
       "20        vectorizer2-RandomForest     0.999801              0.999405   \n",
       "21  vectorizer2-LogisticRegression     0.980890              0.986274   \n",
       "22        vectorizer2-RandomForest     0.999826              0.999580   \n",
       "23        vectorizer2-RandomForest     0.907661              0.800033   \n",
       "24      tf_idf2-LogisticRegression     0.917639              0.929125   \n",
       "\n",
       "       f1_tr  Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0   0.961780     0.858976              0.774507  0.916480  \n",
       "1   0.959021     0.847248              0.757615  0.909235  \n",
       "2   0.947841     0.823792              0.651370  0.897296  \n",
       "3   0.935158     0.837784              0.778253  0.902143  \n",
       "4   0.935158     0.837784              0.778253  0.902143  \n",
       "5   0.988882     0.885741              0.778178  0.933661  \n",
       "6   0.991655     0.888121              0.777245  0.935185  \n",
       "7   0.985819     0.879645              0.777171  0.929812  \n",
       "8   0.989161     0.884464              0.778020  0.932856  \n",
       "9   0.989161     0.884464              0.778020  0.932856  \n",
       "10  0.991655     0.888121              0.777245  0.935185  \n",
       "11  0.913684     0.825128              0.784022  0.893184  \n",
       "12  0.992695     0.899791              0.735254  0.943298  \n",
       "13  0.947677     0.853751              0.704031  0.915177  \n",
       "14  0.968831     0.872503              0.674733  0.927853  \n",
       "15  0.960576     0.863446              0.690045  0.921777  \n",
       "16  0.963657     0.867685              0.685768  0.924564  \n",
       "17  0.950650     0.868149              0.799518  0.921784  \n",
       "18  0.950635     0.868207              0.799551  0.921821  \n",
       "19  0.999885     0.881386              0.549864  0.936050  \n",
       "20  0.999885     0.881386              0.549864  0.936050  \n",
       "21  0.988882     0.885741              0.778178  0.933661  \n",
       "22  0.999900     0.879529              0.537679  0.935219  \n",
       "23  0.946784     0.857641              0.715082  0.917363  \n",
       "24  0.950635     0.868207              0.799551  0.921821  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight = 'balanced', max_iter = 1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "yhat_train = logreg.predict(X_train)\n",
    "yhat_test = logreg.predict(X_test)\n",
    "resultats.evaluer('tf_idf2-LogisticRegression', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------IN TRAIN DATA-------------------------\n",
      "               accuracy = 0.9936549802184678\n",
      "               balanced_accuracy = 0.9960254872887011\n",
      "               f1 = 0.9963324655898977\n",
      "-----------------------------IN TEST DATA--------------------------\n",
      "               accuracy = 0.9019391546679052\n",
      "               balanced_accuracy = 0.7002566174495066\n",
      "               f1 = 0.9452600875060768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_tr</th>\n",
       "      <th>Balanced_accuracy_tr</th>\n",
       "      <th>f1_tr</th>\n",
       "      <th>Accuracy_ts</th>\n",
       "      <th>Balanced_accuracy_ts</th>\n",
       "      <th>f1_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vectorizer1-LogisticRegression</td>\n",
       "      <td>0.929533</td>\n",
       "      <td>0.895021</td>\n",
       "      <td>0.958690</td>\n",
       "      <td>0.835752</td>\n",
       "      <td>0.691591</td>\n",
       "      <td>0.903805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vectorizer1-SVM</td>\n",
       "      <td>0.956804</td>\n",
       "      <td>0.914648</td>\n",
       "      <td>0.975040</td>\n",
       "      <td>0.859150</td>\n",
       "      <td>0.599974</td>\n",
       "      <td>0.921509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vectorizer1-RandomForest</td>\n",
       "      <td>0.903456</td>\n",
       "      <td>0.941034</td>\n",
       "      <td>0.941194</td>\n",
       "      <td>0.696993</td>\n",
       "      <td>0.657366</td>\n",
       "      <td>0.803390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vectorizer2-LogisticRegression</td>\n",
       "      <td>0.962378</td>\n",
       "      <td>0.966572</td>\n",
       "      <td>0.977946</td>\n",
       "      <td>0.868439</td>\n",
       "      <td>0.768055</td>\n",
       "      <td>0.922846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vectorizer2-SVM</td>\n",
       "      <td>0.971286</td>\n",
       "      <td>0.971303</td>\n",
       "      <td>0.983257</td>\n",
       "      <td>0.875639</td>\n",
       "      <td>0.677299</td>\n",
       "      <td>0.929734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vectorizer2-RandomForest</td>\n",
       "      <td>0.998084</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.998895</td>\n",
       "      <td>0.867685</td>\n",
       "      <td>0.550433</td>\n",
       "      <td>0.927932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tf-idf-LogisticRegression</td>\n",
       "      <td>0.914703</td>\n",
       "      <td>0.886639</td>\n",
       "      <td>0.949554</td>\n",
       "      <td>0.836856</td>\n",
       "      <td>0.696250</td>\n",
       "      <td>0.904376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tf_idf1-LogisticRegression</td>\n",
       "      <td>0.914703</td>\n",
       "      <td>0.886639</td>\n",
       "      <td>0.949554</td>\n",
       "      <td>0.836856</td>\n",
       "      <td>0.696250</td>\n",
       "      <td>0.904376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tf_idf1-LogisticRegression-SVM</td>\n",
       "      <td>0.899599</td>\n",
       "      <td>0.939852</td>\n",
       "      <td>0.938677</td>\n",
       "      <td>0.805098</td>\n",
       "      <td>0.621852</td>\n",
       "      <td>0.885913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tf_idf1-SVM</td>\n",
       "      <td>0.899599</td>\n",
       "      <td>0.939852</td>\n",
       "      <td>0.938677</td>\n",
       "      <td>0.805098</td>\n",
       "      <td>0.621852</td>\n",
       "      <td>0.885913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tf_idf1-RandomForest</td>\n",
       "      <td>0.903605</td>\n",
       "      <td>0.941200</td>\n",
       "      <td>0.941289</td>\n",
       "      <td>0.737866</td>\n",
       "      <td>0.631181</td>\n",
       "      <td>0.837397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tf_idf2-LogisticRegression</td>\n",
       "      <td>0.914827</td>\n",
       "      <td>0.926146</td>\n",
       "      <td>0.948890</td>\n",
       "      <td>0.855899</td>\n",
       "      <td>0.786351</td>\n",
       "      <td>0.914082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tf_idf2-SVM</td>\n",
       "      <td>0.993655</td>\n",
       "      <td>0.996025</td>\n",
       "      <td>0.996332</td>\n",
       "      <td>0.901939</td>\n",
       "      <td>0.700257</td>\n",
       "      <td>0.945260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy_tr  Balanced_accuracy_tr  \\\n",
       "0   vectorizer1-LogisticRegression     0.929533              0.895021   \n",
       "1                  vectorizer1-SVM     0.956804              0.914648   \n",
       "2         vectorizer1-RandomForest     0.903456              0.941034   \n",
       "3   vectorizer2-LogisticRegression     0.962378              0.966572   \n",
       "4                  vectorizer2-SVM     0.971286              0.971303   \n",
       "5         vectorizer2-RandomForest     0.998084              0.998656   \n",
       "6        tf-idf-LogisticRegression     0.914703              0.886639   \n",
       "7       tf_idf1-LogisticRegression     0.914703              0.886639   \n",
       "8   tf_idf1-LogisticRegression-SVM     0.899599              0.939852   \n",
       "9                      tf_idf1-SVM     0.899599              0.939852   \n",
       "10            tf_idf1-RandomForest     0.903605              0.941200   \n",
       "11      tf_idf2-LogisticRegression     0.914827              0.926146   \n",
       "12                     tf_idf2-SVM     0.993655              0.996025   \n",
       "\n",
       "       f1_tr  Accuracy_ts  Balanced_accuracy_ts     f1_ts  \n",
       "0   0.958690     0.835752              0.691591  0.903805  \n",
       "1   0.975040     0.859150              0.599974  0.921509  \n",
       "2   0.941194     0.696993              0.657366  0.803390  \n",
       "3   0.977946     0.868439              0.768055  0.922846  \n",
       "4   0.983257     0.875639              0.677299  0.929734  \n",
       "5   0.998895     0.867685              0.550433  0.927932  \n",
       "6   0.949554     0.836856              0.696250  0.904376  \n",
       "7   0.949554     0.836856              0.696250  0.904376  \n",
       "8   0.938677     0.805098              0.621852  0.885913  \n",
       "9   0.938677     0.805098              0.621852  0.885913  \n",
       "10  0.941289     0.737866              0.631181  0.837397  \n",
       "11  0.948890     0.855899              0.786351  0.914082  \n",
       "12  0.996332     0.901939              0.700257  0.945260  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(class_weight = 'balanced')\n",
    "svc.fit(X_train, y_train)\n",
    "yhat_train = svc.predict(X_train)\n",
    "yhat_test = svc.predict(X_test)\n",
    "resultats.evaluer('tf_idf2-SVM', y_train, y_test, yhat_train, yhat_test)\n",
    "resultats.afficher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TALprojet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
